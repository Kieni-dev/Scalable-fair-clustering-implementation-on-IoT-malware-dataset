{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "import data_preprocessing as dp\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import loadtxt\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello \n",
      " Welcome to our Data Preprocessing Platform. \n",
      " \n",
      " \n",
      "Select the data to process.\n",
      "Enter: \n",
      " \t 1 for ICS Dataset \n",
      " \t 2 for SWAT_2019 Dataset\n",
      "\n",
      ": 2\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello \\n Welcome to our Data Preprocessing Platform. \\n \\n \")\n",
    "print(\"Select the data to process.\")\n",
    "print(\"Enter: \\n \\t 1 for ICS Dataset \\n \\t 2 for SWAT_2019 Dataset\\n\")\n",
    "\n",
    "choice = int(input(\": \"))\n",
    "\n",
    "if choice == 1:\n",
    "    \n",
    "    #path to  BATADAL Dataset\n",
    "    pathtoData = ['Dataset/ICS/BATADAL/Physical_BATADAL.npy','ICS']\n",
    "\n",
    "    #path to BATADAL Column Names\n",
    "    columnData = \"Dataset/ICS/BATADAL/Column Names.txt\"\n",
    "    targetName = 'ATT_FLAG'\n",
    "\n",
    "elif choice == 2:\n",
    "    \n",
    "    #path to SWAT_2019 Dataset\n",
    "    pathtoData = ['Dataset/SWAT/SWAT_2019/Physical_SWAT_2019.npy','Physical_SWAT_2019']\n",
    "\n",
    "    #path to SWAT_2019 Column Names\n",
    "    columnData = \"Dataset/SWAT/SWAT_2019/Columns Name.txt\"\n",
    "    targetName = 'P603 Status'\n",
    "    \n",
    "else:\n",
    "    print(\"Invalid Data Selection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dataset/SWAT/SWAT_2019/Physical_SWAT_2019.npy'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pathtoData[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset  Physical_SWAT_2019  Loaded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(14996, 78)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load dataset\n",
    "loaded_Data = dp.getdata(pathtoData[1],pathtoData[0])\n",
    "\n",
    "#checks the number of datapoint and features+target\n",
    "loaded_Data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#coverts the dataset features array to a dataframe and preview\n",
    "df = dp.dataframeConvertion(loaded_Data,columnData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data preprocessing\n",
    "\n",
    "df= dp.InActprocessing(df)\n",
    "target = df [[targetName]]\n",
    "#avoid in balance dataset\n",
    "\n",
    "#save complete dataset\n",
    "dfa = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use PCA to get the best 5,10,20 and 30 features from the dataset\n",
    "df_PCA = dp.get_PCA(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physical_SWAT_20195 exported. It has  5  features selected using PCA\n",
      "Physical_SWAT_201910 exported. It has  10  features selected using PCA\n",
      "Physical_SWAT_201920 exported. It has  20  features selected using PCA\n",
      "Physical_SWAT_201930 exported. It has  30  features selected using PCA\n",
      "Physical_SWAT_201976 exported. It has  76  features.\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "while i < 5:    \n",
    "    if i == 4:\n",
    "        #use entire dataset\n",
    "        df_PCA = dfa\n",
    "        df_processed = pd.DataFrame(df_PCA)\n",
    "        \n",
    "    else:\n",
    "        df_P = df_PCA[i]\n",
    "        df_processed = pd.DataFrame(df_P)\n",
    "        #Add the target and move it to the front of the dataset as \n",
    "        #per the requirement of the fair_clustering algorithm used\n",
    "        df_processed = pd.concat([df_processed,target], axis = 1)\n",
    "    \n",
    "    #move the target to the front \n",
    "    df = dp.addTarget(df_processed)\n",
    "    #remove index\n",
    "    df.reset_index(inplace=True)\n",
    "    df.drop(\"index\",axis=1,inplace=True)\n",
    "\n",
    "    #avoid unbalance dataset error\n",
    "    df1 = df[df[targetName] == 1]\n",
    "    df0 = df[df[targetName] == 0]\n",
    "    dflen1 = len(df1.index)\n",
    "    dflen0 = len(df0.index)\n",
    "\n",
    "    if dflen0 > int((1.2*dflen1)) :\n",
    "        frames = [df0.sample(int(1.2*dflen1)),df1]\n",
    "        df = pd.concat(frames)\n",
    "\n",
    "    elif dflen1 > (int(1.2*dflen0)):\n",
    "        frames = [df1.sample(int(1.2*dflen0)),df0]\n",
    "\n",
    "    df = pd.concat(frames)\n",
    "\n",
    "    #convert file to csv\n",
    "    featureLen = str(len(df.columns)-1)\n",
    "    fileName = pathtoData[1]+featureLen\n",
    "    df.head(len(df.index)).to_csv(fileName, sep=',', header=False, index=False)\n",
    "    \n",
    "    if i == 4:\n",
    "        print(fileName, \"exported. It has \", featureLen, \" features.\")\n",
    "    \n",
    "    else:\n",
    "        print(fileName, \"exported. It has \", featureLen, \" features selected using PCA\" )\n",
    "    \n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
